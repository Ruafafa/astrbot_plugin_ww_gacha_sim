"""
ç½‘ç»œèµ„æºè®¿é—®ä¼˜åŒ–æ¨¡å—
é’ˆå¯¹å›½å†…ç½‘ç»œç¯å¢ƒä¼˜åŒ–èµ„æºè®¿é—®
"""
import httpx
import os
import time
from typing import Optional, Dict, Any
from urllib.parse import urlparse
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ResourcesDownloader:
    """ç½‘ç»œèµ„æºè®¿é—®ä¼˜åŒ–å™¨"""
    
    def __init__(self, sources: str = "https://raw.githubusercontent.com/TomyJan/WutheringWaves-UIResources/3.0/",
        mirror_sources: list[str] = ["https://gitee.com", "https://hub.fastgit.org", "https://ghproxy.com"]
    ):

        self.sources = sources
        self.mirror_sources = mirror_sources

        # è¯·æ±‚å¤´
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        # è®°å½•å½“å‰æ˜¯å¦ä½¿ç”¨é•œåƒæº
        self.using_mirror = False
        self.current_mirror = None
    
    def check_github_connectivity(self) -> bool:
        """
        æ£€æµ‹æ˜¯å¦èƒ½å¤Ÿæ­£å¸¸è®¿é—®GitHub
        è¿”å›Trueè¡¨ç¤ºå¯ä»¥è®¿é—®ï¼ŒFalseè¡¨ç¤ºæ— æ³•è®¿é—®
        """
        test_urls = [
            "https://api.github.com",  # GitHub APIåŸºç¡€åŸŸå
            "https://github.com",  # GitHubä¸»åŸŸå
        ]
        
        for test_url in test_urls:
            try:
                # ä½¿ç”¨è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´è¿›è¡Œæ£€æµ‹
                with httpx.Client(timeout=5.0) as client:
                    response = client.get(test_url, headers=self.headers)
                    if response.status_code == 200:
                        logger.info(f"âœ… æˆåŠŸè®¿é—®GitHub: {test_url}")
                        return True
            except httpx.TimeoutException:
                logger.warning(f"âŒ è®¿é—®GitHubè¶…æ—¶: {test_url}")
            except httpx.RequestError as e:
                logger.error(f"âŒ è¯·æ±‚é”™è¯¯æ—¶è®¿é—®GitHub: {test_url}, Error: {e}")
            except Exception as e:
                logger.error(f"âŒ è®¿é—®GitHubæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {test_url}, Error: {e}")

        logger.error("âŒ æ— æ³•è®¿é—®GitHubæœåŠ¡")
        return False
    
    def check_system_proxy(self) -> Dict[str, Any]:
        """
        æ£€æµ‹ç³»ç»Ÿæ˜¯å¦é…ç½®äº†æœ‰æ•ˆçš„ç½‘ç»œä»£ç†
        è¿”å›ä»£ç†é…ç½®ä¿¡æ¯
        """
        proxy_env_vars = ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']
        proxies = {}
        
        for var in proxy_env_vars:
            if var in os.environ:
                proxies[var] = os.environ[var]
        
        if proxies:
            logger.info(f"âœ… æ£€æµ‹åˆ°ç³»ç»Ÿä»£ç†é…ç½®: {proxies}")
        else:
            logger.warning("âŒ æœªæ£€æµ‹åˆ°ç³»ç»Ÿä»£ç†é…ç½®")
        return proxies
    
    def switch_to_mirror(self, original_url: str) -> Optional[str]:
        """
        åˆ‡æ¢åˆ°é¢„è®¾çš„GitHubé•œåƒæº
        è¿”å›é•œåƒURLï¼Œè‹¥æ‰€æœ‰é•œåƒéƒ½ä¸å¯ç”¨åˆ™è¿”å›None
        """
        logger.info(f"ğŸ”„ å¼€å§‹åˆ‡æ¢GitHubé•œåƒæºï¼ŒåŸå§‹URL: {original_url}")
        
        for mirror in self.mirror_sources:
            try:
                # æµ‹è¯•é•œåƒæºæ˜¯å¦å¯ç”¨
                test_url = f"{mirror}/"
                with httpx.Client(timeout=5.0) as client:
                    response = client.get(test_url, headers=self.headers)
                    if response.status_code in [200, 301, 302]:
                        # æ„å»ºé•œåƒURL - é€šç”¨æ–¹æ³•ï¼šæå–ç›¸å¯¹è·¯å¾„å¹¶ç»“åˆé•œåƒæº
                        # ä»åŸå§‹URLä¸­æå–ç›¸å¯¹äºsourcesçš„è·¯å¾„
                        relative_path = original_url
                        if hasattr(self, 'sources') and self.sources:
                            # å¦‚æœåŸå§‹URLä»¥sourceså¼€å¤´ï¼Œåˆ™æå–ç›¸å¯¹è·¯å¾„
                            if original_url.startswith(self.sources):
                                relative_path = original_url[len(self.sources):]
                        
                        # ç¡®ä¿ç›¸å¯¹è·¯å¾„å‰é¢æœ‰ä¸€ä¸ªæ–œæ 
                        if not relative_path.startswith('/'):
                            relative_path = '/' + relative_path
                            
                        # ç»„åˆé•œåƒæºå’Œç›¸å¯¹è·¯å¾„
                        if "ghproxy.com" in mirror:
                            # ghproxy.com: ä½¿ç”¨ä»£ç†æ ¼å¼ï¼Œå°†åŸURLä½œä¸ºå‚æ•°
                            mirror_url = f"{mirror.rstrip('/')}/{original_url}"
                        else:
                            # å…¶ä»–é•œåƒæºï¼šç›´æ¥ç»„åˆé•œåƒæºå’Œç›¸å¯¹è·¯å¾„
                            mirror_url = f"{mirror.rstrip('/')}{relative_path}"
                        
                        self.using_mirror = True
                        self.current_mirror = mirror
                        logger.info(f"âœ… æˆåŠŸåˆ‡æ¢åˆ°é•œåƒæº: {mirror}, é•œåƒURL: {mirror_url}")
                        return mirror_url
                    else:
                        logger.warning(f"Mirror source unavailable: {mirror}, status code: {response.status_code}")
            except httpx.TimeoutException:
                logger.warning(f"Mirror source timeout: {mirror}")
            except httpx.RequestError as e:
                logger.error(f"Request error when accessing mirror: {mirror}, Error: {e}")
                print(f"âŒ æ— æ³•è®¿é—®é•œåƒæº: {mirror}, é”™è¯¯: {e}")
            except Exception as e:
                logger.error(f"Unexpected error when accessing mirror: {mirror}, Error: {e}")
                print(f"âŒ æ— æ³•è®¿é—®é•œåƒæº: {mirror}, é”™è¯¯: {e}")
        
        print("âŒ æ‰€æœ‰é•œåƒæºéƒ½ä¸å¯ç”¨")
        logger.error("All mirror sources are unavailable")
        return None
    
    def download_with_retry(self, url: str, max_retries: int = 3, timeout: int = 15) -> Optional[bytes]:
        """å¸¦é‡è¯•æœºåˆ¶çš„ä¸‹è½½åŠŸèƒ½"""
        # æ£€æŸ¥URLæ˜¯å¦æœ‰æ•ˆ
        if not self.is_valid_resource_url(url):
            logger.warning(f"âŒ æ— æ•ˆçš„URL: {url}")
            return None
        
        # ä»…å¯¹GitHub URLè¿›è¡Œç‰¹æ®Šå¤„ç†
        is_github_url = "github" in url.lower()
        if is_github_url:
            # 1. æ‰§è¡ŒGitHubè¿é€šæ€§æµ‹è¯•
            try:
                can_access_github = self.check_github_connectivity()
            except Exception as e:
                logger.error(f"âŒ æ£€æŸ¥GitHubè¿é€šæ€§æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
                can_access_github = False
            
            if not can_access_github:
                # 2. æ£€æµ‹ç³»ç»Ÿæ˜¯å¦é…ç½®äº†æœ‰æ•ˆçš„ç½‘ç»œä»£ç†
                try:
                    system_proxies = self.check_system_proxy()
                except Exception as e:
                    logger.error(f"âŒ æ£€æŸ¥ç³»ç»Ÿä»£ç†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
                    system_proxies = {}
                
                if not system_proxies:
                    # 3. è‡ªåŠ¨åˆ‡æ¢è‡³é¢„è®¾çš„GitHubé•œåƒæº
                    try:
                        mirror_url = self.switch_to_mirror(url)
                        if mirror_url:
                            url = mirror_url
                        else:
                            # æ‰€æœ‰é•œåƒæºéƒ½ä¸å¯ç”¨
                            logger.error("âŒ æ— æ³•è®¿é—®GitHubä¸”æ‰€æœ‰é•œåƒæºéƒ½ä¸å¯ç”¨ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ‰‹åŠ¨é…ç½®ä»£ç†")
                            return None
                    except Exception as e:
                        logger.error(f"âŒ é•œåƒåˆ‡æ¢å¤±è´¥: {e}")
                        return None
        
        # 4. å°è¯•ä¸‹è½½èµ„æº
        for attempt in range(max_retries):
            try:
                logger.info(f"Download attempt {attempt + 1}/{max_retries}: {url}")
                
                with httpx.Client(timeout=httpx.Timeout(timeout=timeout)) as client:
                    response = client.get(url, headers=self.headers)
                    if response.status_code == 200:
                        logger.info(f"âœ… ä¸‹è½½æˆåŠŸ: {url}")
                        return response.content
                    else:
                        logger.warning(f"âŒ ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, URL: {url}")
            except httpx.TimeoutException:
                logger.warning(f"âŒ ä¸‹è½½è¶…æ—¶ï¼Œå°è¯• {attempt + 1}/{max_retries}: {url}")
            except httpx.RequestError as e:
                logger.error(f"âŒ ä¸‹è½½è¯·æ±‚é”™è¯¯ï¼Œå°è¯• {attempt + 1}/{max_retries}: {url}, Error: {e}")
            except Exception as e:
                logger.error(f"âŒ ä¸‹è½½å°è¯• {attempt + 1} å¤±è´¥: {e}, URL: {url}")
            
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                logger.info(f"â±ï¸  ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
        
        # 5. æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
        logger.error(f"âŒ æ‰€æœ‰ä¸‹è½½å°è¯•éƒ½å¤±è´¥: {url}")
        return None
    
    def is_valid_resource_url(self, url: str) -> bool:
        """æ£€æŸ¥èµ„æºURLæ˜¯å¦æœ‰æ•ˆ"""
        try:
            parsed = urlparse(url)
            is_valid = all([parsed.scheme, parsed.netloc])
            if not is_valid:
                logger.warning(f"Invalid URL format: {url}")
            return is_valid
        except Exception as e:
            logger.error(f"Error parsing URL: {url}, Error: {e}")
            return False